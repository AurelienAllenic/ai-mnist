{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "215758ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9dc58e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2f21d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# functions to show an image\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d67990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.585\n",
      "[1,  4000] loss: 0.198\n",
      "[1,  6000] loss: 0.135\n",
      "[1,  8000] loss: 0.127\n",
      "[1, 10000] loss: 0.112\n",
      "[1, 12000] loss: 0.106\n",
      "[1, 14000] loss: 0.095\n",
      "[2,  2000] loss: 0.085\n",
      "[2,  4000] loss: 0.078\n",
      "[2,  6000] loss: 0.075\n",
      "[2,  8000] loss: 0.074\n",
      "[2, 10000] loss: 0.067\n",
      "[2, 12000] loss: 0.072\n",
      "[2, 14000] loss: 0.065\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f151c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cnn.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7bbccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  7     2     1     0    \n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951c8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f787a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  7     2     1     0    \n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce7a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1c762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0     is 99.5 %\n",
      "Accuracy for class: 1     is 99.5 %\n",
      "Accuracy for class: 2     is 98.6 %\n",
      "Accuracy for class: 3     is 98.5 %\n",
      "Accuracy for class: 4     is 99.9 %\n",
      "Accuracy for class: 5     is 98.9 %\n",
      "Accuracy for class: 6     is 97.8 %\n",
      "Accuracy for class: 7     is 99.2 %\n",
      "Accuracy for class: 8     is 98.0 %\n",
      "Accuracy for class: 9     is 97.5 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a0f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777163f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52743220",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = data[0].to(device), data[1].to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
